<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>API Reference</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight {
  color: #faf6e4;
  background-color: #122b3b;
}
.highlight .gl {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .c, .highlight .cd, .highlight .cm, .highlight .c1, .highlight .cs {
  color: #6c8b9f;
  font-style: italic;
}
.highlight .cp {
  color: #b2fd6d;
  font-weight: bold;
  font-style: italic;
}
.highlight .err {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .gr {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .k, .highlight .kd, .highlight .kv {
  color: #f6dd62;
  font-weight: bold;
}
.highlight .o, .highlight .ow {
  color: #4df4ff;
}
.highlight .p, .highlight .pi {
  color: #4df4ff;
}
.highlight .gd {
  color: #cc0000;
}
.highlight .gi {
  color: #b2fd6d;
}
.highlight .ge {
  font-style: italic;
}
.highlight .gs {
  font-weight: bold;
}
.highlight .gt {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .kc {
  color: #f696db;
  font-weight: bold;
}
.highlight .kn {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kp {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kr {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gh {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gu {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kt {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .no {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nc {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nd {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nn {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .bp {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .ne {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nl {
  color: #ffb000;
  font-weight: bold;
}
.highlight .nt {
  color: #ffb000;
  font-weight: bold;
}
.highlight .m, .highlight .mf, .highlight .mh, .highlight .mi, .highlight .il, .highlight .mo, .highlight .mb, .highlight .mx {
  color: #f696db;
  font-weight: bold;
}
.highlight .ld {
  color: #f696db;
  font-weight: bold;
}
.highlight .ss {
  color: #f696db;
  font-weight: bold;
}
.highlight .s, .highlight .sb, .highlight .sd, .highlight .s2, .highlight .sh, .highlight .sx, .highlight .sr, .highlight .s1 {
  color: #fff0a6;
  font-weight: bold;
}
.highlight .se {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .sc {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .si {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .nb {
  font-weight: bold;
}
.highlight .ni {
  color: #999999;
  font-weight: bold;
}
.highlight .w {
  color: #BBBBBB;
}
.highlight .nf {
  color: #a8e1fe;
}
.highlight .py {
  color: #a8e1fe;
}
.highlight .na {
  color: #a8e1fe;
}
.highlight .nv, .highlight .vc, .highlight .vg, .highlight .vi {
  color: #a8e1fe;
  font-weight: bold;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
    <!-- Google Analytics: change UA-XXXXX-X to be your site's ID -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-72314368-1', 'auto');
      ga('send', 'pageview');
    </script>
    <!-- Built with love using Web Starter Kit -->
  </head>

  <body class="index" data-languages="[]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" />
      </span>
    </a>
    <div class="tocify-wrapper">
      <img src="images/logo.png" />
        <div class="lang-selector">
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <div id="toc">
      </div>
        <ul class="toc-footer">
            <li><a href='https://github.com/kengz/aiva'>AIVA Github</a></li>
            <li><a href='https://github.com/kengz/aiva-doc'>AIVA documentation Github</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id="aiva">AIVA <a href="http://badge.fury.io/gh/kengz%2Faiva"><img alt="GitHub version" src="https://badge.fury.io/gh/kengz%2Faiva.svg" /></a> <a href="https://travis-ci.org/kengz/aiva"><img alt="Build Status" src="https://travis-ci.org/kengz/aiva.svg?branch=master" /></a> <a href="https://codeclimate.com/github/kengz/aiva"><img alt="Code Climate" src="https://codeclimate.com/github/kengz/aiva/badges/gpa.svg" /></a> <a href="https://codeclimate.com/github/kengz/aiva/coverage"><img alt="Test Coverage" src="https://codeclimate.com/github/kengz/aiva/badges/coverage.svg" /></a> <a href="https://gemnasium.com/kengz/aiva"><img alt="Dependency Status" src="https://gemnasium.com/kengz/aiva.svg" /></a> <a href="https://raw.githubusercontent.com/hyperium/hyper/master/LICENSE"><img alt="MIT licensed" src="https://img.shields.io/badge/license-MIT-blue.svg" /></a> <a href="https://github.com/kengz/aiva"><img alt="GitHub forks" src="https://img.shields.io/github/forks/kengz/aiva.svg?style=social&amp;label=Fork" /></a> <a href="https://github.com/kengz/aiva"><img alt="GitHub stars" src="https://img.shields.io/github/stars/kengz/aiva.svg?style=social&amp;label=Star" /></a></h1>

<p><strong>AIVA</strong> (A.I. Virtual Assistant): General-purpose virtual assistant for developers. <a href="http://kengz.me/aiva/">http://kengz.me/aiva/</a></p>

<p>It is a <strong>bot-generalization</strong>: you can implement any features, use with major AI tools, deploy across platforms, and code in multiple languages.</p>

<table><thead>
<tr>
<th style="text-align: left">AIVA is</th>
<th>Details</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">general-purpose</td>
<td>An app interface, AI assistant, anything!</td>
</tr>
<tr>
<td style="text-align: left">cross-platform</td>
<td>Deploy simultaneously on <strong>Slack, Telegram, Facebook</strong>, or any <a href="https://github.com/github/hubot/blob/master/docs/adapters.md">hubot adapters</a></td>
</tr>
<tr>
<td style="text-align: left">multi-language</td>
<td>Cross-interaction among <code class="prettyprint">Node.js</code>, <code class="prettyprint">Python</code>, <code class="prettyprint">Ruby</code>, etc. using <code class="prettyprint">SocketIO</code>.</td>
</tr>
<tr>
<td style="text-align: left">built-in with AI tools (not preinstalled since v4)</td>
<td>Tensorflow, SkFlow, Scikit, Pandas, Indico.ml, spaCy, Watson, Google APIs</td>
</tr>
<tr>
<td style="text-align: left">hackable</td>
<td>It extends <a href="https://github.com/github/hubot">Hubot</a>. Add your own modules!</td>
</tr>
<tr>
<td style="text-align: left">powerful, easy to use</td>
<td>Check out <a href="http://kengz.me/aiva/#setup">setup</a> and <a href="http://kengz.me/aiva/#features">features</a></td>
</tr>
</tbody></table>

<blockquote>
<p>To see what they mean, say you have a todo-list feature for AIVA, written in Node.js and leverages NLP and ML from Python. Set your todo list earlier from Slack on desktop? You can access it from Telegram or Facebook on mobile.</p>

<p>Deepdream in AIVA (checkout v3.2.1), only took a few hours on the Deepdream module, and deployed it in AIVA in just minutes. Runs on Fb and Telegram simulteneously: <img alt="Deepdream in AIVA" src="http://kengz.me/aiva/images/deepdream.gif" /></p>
</blockquote>

<p>We see people spending a lot of time building bots instead of focusing on what they want to do. It still requires much effort to just get a bot up and running. Moreover, the bot built is often confined to a single language, single platform, and without AI capabilities.</p>

<p>Why restrict when you can have all of it? Why build multiple bots when you can have one that plugs into all platforms and runs all languages?</p>

<p>AIVA exists to help with that - we do the heavy-lifting and build a ready-to-use bot; it is general purpose, multi-language, cross-platform, with robust design and tests, to suite your needs. </p>

<p>AIVA gives you powerful bot tools, saves you the time to build from scratch, and allows you to focus on what you want to do. Morever, you can <strong>build once, run everywhere</strong> with AIVA&rsquo;s multi-adapter <a href="http://kengz.me/aiva/#adapters">(Slack, Telegram, Fb)</a>.</p>

<h2 id="installation">Installation</h2>

<p>1. Fork this repo so you can pull the new releases later:</p>

<p>&nbsp; &nbsp; <a href="https://github.com/kengz/aiva"><img alt="GitHub forks" src="https://img.shields.io/github/forks/kengz/aiva.svg?style=social&amp;label=Fork" /></a> <a href="https://github.com/kengz/aiva"><img alt="GitHub stars" src="https://img.shields.io/github/stars/kengz/aiva.svg?style=social&amp;label=Star" /></a></p>

<p>2. Clone <strong>your forked repository</strong>:</p>
<pre class="highlight shell"><code>git clone https://github.com/YOURUSERNAME/aiva.git
</code></pre>

<h2 id="setup"><a name="setup"></a>Setup</h2>

<p>The line below runs <code class="prettyprint">bin/setup &amp;&amp; bin/copy-config &amp;&amp; npm install</code>:</p>
<pre class="highlight shell"><code>npm run setup
</code></pre>

<p>Then edit <code class="prettyprint">config/</code> files: <code class="prettyprint">default.json</code>(development), <code class="prettyprint">production.json</code>(production, optional), <code class="prettyprint">db.json</code>(mysql)</p>

<p>The command installs the dependencies via <code class="prettyprint">bin/install &amp;&amp; npm install</code>, and prepare the database for aiva to run on. The dependencies are minimal: <code class="prettyprint">nodejs&gt;=6</code>, <code class="prettyprint">python3</code>, and <code class="prettyprint">mysql</code>.</p>

<p>See <code class="prettyprint">bin/install</code> for the full list, and customize your own. This also runs the same sequence as the CircleCI build in <code class="prettyprint">circle.yml</code>.</p>

<p><strong>Docker</strong>. We also offer a Docker image <a href="https://hub.docker.com/r/kengz/aiva/">kengz/aiva</a>. It runs the same except with an extra layer of Docker. See <a href="http://kengz.me/aiva/#docker-installation">Docker installation</a> for more.</p>

<h2 id="run"><a name="run"></a>Run</h2>
<pre class="highlight shell"><code>npm start <span class="c"># runs 'aivadev' in development mode</span>
</code></pre>
<pre class="highlight shell"><code><span class="c"># Add flags for more modes</span>
npm start --debug <span class="c"># activate debug logger</span>
npm start production <span class="c"># runs 'aiva' in production mode</span>
</code></pre>

<p>See <a href="http://kengz.me/aiva/#commands">Commands</a> for more. This will start AIVA with the default hubot adapters: Slack, Telegram, Facebook (only if activated). See <a href="http://kengz.me/aiva/#adapters"><strong>Adapters</strong></a> for connecting to different chat platforms.</p>

<blockquote>
<p>AIVA saying hi, translating, running deep neural net; on Slack, Telegram, Facebook:
<img alt="AIVA on Slack, Telegram" src="http://kengz.me/aiva/images/npm_start.png" /></p>
</blockquote>

<p>Check <a href="http://kengz.me/aiva/#setup-tips"><strong>Setup tips</strong></a> for help.</p>

          <h1 id="features"><a name="features"></a>Features</h1>

<p>This gives a top level overview of the features. See <a href="#modules">Modules</a> to find usable functions for developers.</p>

<table><thead>
<tr>
<th style="text-align: left">Feature</th>
<th>Implemented?</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left"><a href="#setup2">fast setup</a></td>
<td>yes</td>
</tr>
<tr>
<td style="text-align: left"><a href="#docker">docker</a></td>
<td>yes</td>
</tr>
<tr>
<td style="text-align: left"><a href="#cross-platform">cross-platform</a></td>
<td>yes</td>
</tr>
<tr>
<td style="text-align: left"><a href="#custom-msg">customMessage</a></td>
<td>pending</td>
</tr>
<tr>
<td style="text-align: left"><a href="#graph-brain">graph brain</a></td>
<td>pending</td>
</tr>
<tr>
<td style="text-align: left"><a href="#multi-language">multi-language</a></td>
<td>yes</td>
</tr>
<tr>
<td style="text-align: left"><a href="#builtin-ai">AI tools</a></td>
<td>yes</td>
</tr>
<tr>
<td style="text-align: left"><a href="#theoretical">theoretical power</a></td>
<td>yes</td>
</tr>
</tbody></table>

<h2 id="fast-setup"><a name="setup2"></a>fast setup</h2>

<p><a href="#setup">3 steps</a> to get a bot installed and running. It once took me just 15 seconds to deploy a bot for an unexpected demo. </p>

<p><em>P/S &ldquo;fast&rdquo; implies the least number of steps; dependency installation can be heavy and long.</em></p>

<h2 id="docker"><a name="docker"></a>Docker</h2>

<p>Complex projects tend to be difficult to install and distribute. Docker has become a preferred solution, especially for heavy machine learning projects. Docker also provides a fast and safe development environment through containerization.</p>
<pre class="highlight shell"><code>docker pull kengz/aiva
</code></pre>

<p>AIVA is quite heavy on dependencies, understandably. So we&rsquo;ve add an <a href="https://hub.docker.com/r/kengz/aiva/">AIVA docker image <code class="prettyprint">kengz/aiva</code></a> since <code class="prettyprint">v3.2.0</code>, and development is seamless with it. See <a href="#docker-installation">Docker installation</a>.</p>

<h2 id="cross-platform"><a name="cross-platform"></a>cross-platform</h2>

<p>The Facebook bot paradigm is &ldquo;why use multiple apps when you can access them from one bot?&rdquo;. We dare to ask &ldquo;why talk to the bot from one platform instead of everywhere?&rdquo; With AIVA we can <strong>build once, run everywhere</strong>.</p>

<h3 id="omnipresence">Omnipresence</h3>

<p>This inspires the <strong>omnipresence</strong> feature: a bot that recognizes who you are, and can continue conversation in any supported platforms. We talk to our friends everywhere, and they don&rsquo;t forget us when we switch apps. Bots should do the same too.</p>

<p>In short: <strong>one brain, multiple interfaces</strong>. AIVA&rsquo;s hubot base allows for generality, and it can tap into multiple platforms by using different <a href="#adapters">adapters</a>. Unlike the original hubot though, she can exist simultaneously on multiple platforms by having several interface instances plugged into the respective adapters, and all share the same brain, which serves as the central memory.</p>

<p>See <a href="#adapters">adapters</a> for more.</p>

<h2 id="custommessage"><a name="custom-msg"></a>customMessage</h2>

<p>Sending plain texts to different adapters is straightforward. However, sometimes we wish to take advantage of the available custom formatting of a platform, such as Slack attachment or Facebook rich messages.</p>

<p>These special messages can be sent via <code class="prettyprint">robot.adapter.customMessage(attachments)</code> - a method that most adapters implement (Slack, Telegram, Facebook adapters have it). All we need to do is to format the attachments properly by detecting the current adapter using <code class="prettyprint">robot.adapterName</code>, then format the attachments to the right format with <code class="prettyprint">customFormat</code>.</p>

<p>See <a href="#adapters">adapters</a> for more.</p>

<aside class="notice">
Implementation is complete for Slack, Telegram, but partial for Facebook adapter since it&rsquo;s quite new. We are working with the adapter&rsquo;s author to complete this very soon - will be done in the next release soon.
</aside>

<h2 id="graph-brain"><a name="graph-brain"></a>graph brain</h2>

<p>The brain of AIVA is a graph database; it is the central memory that coordinates with different adapters, allowing it to be consistent across the platforms; for example, it can remember who you are or your todo list, even as you switch apps.</p>

<p>Graph is a very generic and natural way of encoding information, especially for information that doesn&rsquo;t always follow a fixed schema. A knowledge base is often implemented as a graph (wordNet, conceptNet, google graph, facebook graph, etc.) due to the adhoc and connected nature of generic knowledge. Thus, we think it&rsquo;s the natural choice for AIVA.</p>

<p>Although graph and non-graph databases can both be Turing-complete, graphs tend to have a lower working complexity in practice, and it&rsquo;s data units can be schema-free. Turing completeness ensures that the database can do everything a computer supposedly can; lower complexity makes development easier, schema-free allows knowledge creation on-the-fly.</p>

<aside class="notice">
User serialization that depends on the brain is complete for Slack, but partial for Telegram, Facebook. They will be done in the next release soon.
</aside>

<h2 id="multi-language"><a name="multi-language"></a>multi-language</h2>

<p><strong>Unite we stand</strong>. When different languages work together, we can access a much larger set of development tools. Also, we wish that a developer can use the AIVA regardless of his/her favorite programming language. </p>

<p>For more, see <a href="#polyglot">Polyglot environment</a> and <a href="#clients">Socket.io clients</a> for how it&rsquo;s done. We now support <code class="prettyprint">node.js, python, ruby</code>.</p>

<h2 id="ai-tools"><a name="builtin-ai"></a>AI tools</h2>

<p>AIVA can be used with a set of well-rounded set AI/machine learning tools - each is the most advanced of its type. The recommendations below saves you the tideous hunt, installation, and setup. </p>

<p>Thanks to the multi-language feature, we can easily access the machine learning universe of Python. For example, <a href="https://github.com/kengz/aiva/tree/master/lib/py/ais/" target="_blank"><code>lib/py/ais/</code></a> contains a sample Tensorflow training script <a href="https://github.com/kengz/aiva/tree/master/lib/py/ais/dnn_titanic_train.py" target="_blank"><code>dnn_titanic_train.py</code></a>, and a script to deploy that DNN for usage <a href="https://github.com/kengz/aiva/tree/master/lib/py/ais/dnn_titanic_deploy.py" target="_blank"><code>dnn_titanic_deploy.py</code></a>. It is interfaced through <a href="https://github.com/kengz/aiva/tree/master/scripts/dnn_titanic.js" target="_blank"><code>scripts/dnn_titanic.js</code></a> that allows you to use run predictions.</p>

<p>The list of AI modules and their respective language:</p>

<table><thead>
<tr>
<th style="text-align: left">AI/ML</th>
<th>type</th>
<th>lang</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left"><a href="https://www.tensorflow.org">Tensorflow</a></td>
<td>Neural Nets</td>
<td>Python</td>
</tr>
<tr>
<td style="text-align: left"><a href="http://scikit-learn.org/stable/">scikit-learn</a></td>
<td>Generic ML algorithms</td>
<td>Python</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/tensorflow/skflow">SkFlow</a></td>
<td>Tensorflow + Scikit-learn</td>
<td>Python</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://spacy.io">spaCy</a></td>
<td>NLP</td>
<td>Python</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/wit-ai/node-wit">Wit.ai</a></td>
<td>NLP for developers</td>
<td>Node.js client</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://indico.io">Indico.io</a></td>
<td>text+image analysis</td>
<td>(REST API) Node.js client</td>
</tr>
<tr>
<td style="text-align: left"><a href="http://www.ibm.com/cloud-computing/bluemix/watson/">IBM Watson</a></td>
<td>cognitive computing</td>
<td>Node.js client</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://console.developers.google.com/apis">Google API</a></td>
<td>multiple</td>
<td>Node.js client</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/Planeshifter/node-concept-net">ConceptNet</a></td>
<td>semantic network</td>
<td>(REST API) Node.js interface</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/NaturalNode/natural">NodeNatural</a></td>
<td>NLP</td>
<td>Node.js</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/moos/wordpos">wordpos</a></td>
<td>WordNet POS</td>
<td>Node.js</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://github.com/matthewmueller/date">date.js</a></td>
<td>time-parsing</td>
<td>Node.js</td>
</tr>
</tbody></table>

<p>These tools are put close together in a <a href="#polyglot">polyglot environment</a>, so you can start combining them in brand new ways. An example is the generic NLP parser for parsing user input into intent and functional arguments.</p>

<h2 id="theoretical-power"><a name="theoretical"></a>theoretical power</h2>

<p>AIVA is based on a theoretical interface <a href="http://kengz.me/aiva/#human-turing-machine-interface">HTMI</a> and a brain <a href="http://kengz.me/aiva/#contextual-graph-knowledge-base">CGKB</a> that is <em>human-bounded Turing complete</em>. The theorem establishes that HTMI can be used by a human to solve any problems or perform any functions she enumerates that are solvable by a Turing Machine. Complete implementation is still underway.</p>

<p>Why is this important? Because for far too many times people have tried to solve problems that are unsolvable. Many of the bots out there are actually very restrictive. To allow developers to solve problems with full power, and with easy, we have built a general-purpose tool and made it theoretically complete, so you can focus on solving your problem.</p>

          <h1 id="adapters"><a name="adapters"></a>Adapters</h1>

<p>AIVA can simultaneously connect to multiple chat platforms and still behave as one entity. This allows you to <strong>build once, run everywhere</strong>.</p>

<p>It utilizes <a href="https://github.com/github/hubot/blob/master/docs/adapters.md">hubot&rsquo;s adapters</a>. So, feel free to add any as you wish. AIVA comes with <strong>Slack, Telegram, Fb</strong> adapters. See <code class="prettyprint">config/default.json</code> at key <code class="prettyprint">ADAPTERS</code> to activate or add more.</p>

<p>For each adapter, we encourage you to create two tokens, for <strong>production</strong> and <strong>development</strong> respectively. The credentials go into <code class="prettyprint">config/default.json</code>(development), and <code class="prettyprint">config/production.json</code>.</p>

<p>The webhooks for adapters are auto-set in <a href="#ngrok"><code class="prettyprint">ngrok</code></a> in <code class="prettyprint">src/aiva.js</code>; you don&rsquo;t even need to provide a webhook url.</p>

<p>As mentioned, we can use the custom message formatting of a platform, such as Slack attachment or Facebook rich messages. You can check the adapter by <code class="prettyprint">robot.adapterName</code> to format message accordingly, then send it using the method <code class="prettyprint">robot.adapter.customMessage</code> for any adapter. More below.</p>

<aside class="notice">
customMessage will be generalized soon - we are still working with the developers of the adapters, and will then provide better in-code examples.
</aside>

<h2 id="slack">Slack</h2>

<p><a href="https://github.com/slackhq/hubot-slack">hubot-slack</a> comes with AIVA. It uses Slack&rsquo;s RTC API. Create your bot and get the token <a href="https://my.slack.com/services/new/bot">here</a>.</p>

<p>To use customMessage, see the <a href="https://github.com/slackhq/hubot-slack/issues/170#issuecomment-113315455">example (pending update)</a>, invoked when <code class="prettyprint">robot.adapterName == &#39;slack&#39;</code>. Refer to the <a href="https://api.slack.com/docs/attachments">Slack attachments</a> for formatting.</p>

<h2 id="telegram">Telegram</h2>

<p><a href="https://github.com/lukefx/hubot-telegram">hubot-telegram</a> comes with AIVA. Create your bot and get the token <a href="https://core.telegram.org/bots#3-how-do-i-create-a-bot">here</a>.</p>

<aside class="notice">
It&rsquo;s optional to provide a webhook url in config/ with TELEGRAM_WEBHOOK; it is set up automatically in <a href="#ngrok"><code>index.js with ngrok</code></a>.
</aside>

<p>To use customMessage, see the <a href="https://github.com/lukefx/hubot-telegram#telegram-specific-functionality-ie-stickers-images">example</a>, invoked when <code class="prettyprint">robot.adapterName == &#39;telegram&#39;</code>. Refer to <a href="https://core.telegram.org/bots/api">Telegram bot API</a> for formatting.</p>

<h2 id="facebook">Facebook</h2>

<p><a href="https://github.com/chen-ye/hubot-fb">hubot-fb</a> comes with AIVA. Create your bot by creating a Fb App and Page, as detailed <a href="https://developers.facebook.com/docs/messenger-platform/quickstart">here</a>. Set the <code class="prettyprint">FB_PAGE_ID, FB_APP_ID, FB_APP_SECRET, FB_PAGE_TOKEN</code> as explained in the adapter&rsquo;s page <a href="https://github.com/kengz/hubot-fb#configuration">hubot-fb</a>.</p>

<aside class="notice">
It&rsquo;s optional to provide a webhook url; it is set up automatically in <a href="#ngrok"><code>aiva.js with ngrok</code></a>.
</aside>

<aside class="warning">
Note that Facebook takes 10 mins to update webhook, so you may need to wait till then to start receiving messages. We advice using a persistent url in config/ key FB_WEBHOOK, e.g. a Heroku url, or ngrok custom domain url; see <a href="#ngrok"><code>Tips on Webhook with ngrok</code></a>.
</aside>

<p>To use customMessage, see <a href="https://github.com/chen-ye/hubot-fb#sending-rich-messages-templates-images">the examples</a>, invoked when <code class="prettyprint">robot.adapterName == &#39;fb&#39;</code>. Refer to the <a href="https://developers.facebook.com/docs/messenger-platform/send-api-reference">Send API</a> for formatting.</p>

          <h1 id="development-guide"><a name="dev-guide"></a>Development Guide</h1>

<p>AIVA is created as an A.I. general purpose interface for developers. You can implement any features, use it simultaneously on the major platforms, and code in multiple languages. This solves the problem that many bots out there are are too specific, often bounded to one chat platform, and can only be developed in one language.</p>

<p>Since it is a generic interface, you can focus on writing your app/module. When done, plugging it into AIVA shall be way more trivial than writing a whole app with a MEAN stack or Rails to serve it.</p>

<h3 id="production-and-development">Production and Development</h3>

<p>Per common practice, we distinguish between production and development version using <code class="prettyprint">NODE_ENV</code> environment variables. So we generate two sets of keys for two bots:</p>

<aside class="success">
Use &ldquo;aiva&rdquo; for production, &ldquo;aivadev&rdquo; for development. They can coexist without system conflicts.
</aside>

<h3 id="commands"><a name="commands"></a>Commands</h3>

<p>All the commands are coded through <code class="prettyprint">package.json</code> and can be ran from <code class="prettyprint">npm</code>:</p>
<pre class="highlight shell"><code>npm start <span class="c"># run development mode 'aivadev'</span>
npm start --debug <span class="c"># activate debug logger</span>
npm start production <span class="c"># runs production mode 'aiva'</span>
npm stop <span class="c"># stop the bots</span>
npm <span class="nb">test</span> <span class="c"># run unit tests</span>
forever list <span class="c"># see the list of bots running</span>
</code></pre>

<h3 id="docker">Docker</h3>

<p>All the commands/scripts are compatible for use with/without Docker. The Docker image syncs the repo volume, so you can edit the source code and run the terminal commands as usual. The shell will enter a Docker container and run the same thing as it would on a local machine, so you can barely feel the difference when developing.</p>

<p>For Dockers, there are 2 containers: <code class="prettyprint">aiva-production</code> and <code class="prettyprint">aiva-development</code>, which provide good isolation. You can develop safely in parallel without needing to take down your deployed version.</p>

<p>See <a href="#dockerization">Dockerization</a> for how AIVA is packaged into Docker.</p>

<p>Everything runs pretty much the same with Docker, except for a layer of wrapped abstractions. There are some extra commands for Docker:</p>
<pre class="highlight shell"><code>npm run enter <span class="c"># enter a parallel bash session in the Docker container</span>
npm run reset <span class="c"># stop and remove the container</span>
</code></pre>

<aside class="notice">
For Docker, <code>npm start</code> launches the primary bash session, which is used only for <code>supervisord</code>. Use <code>npm run enter</code> to launch parallel bash sessions for all other purposes.
</aside>

<h3 id="custom-dependencies">Custom Dependencies</h3>

<p>The Docker containers on start will auto install any new dependencies specified in the right config files. They&rsquo;re listed in <a href="#project-dependencies">Project Dependencies</a>.</p>

<h2 id="polyglot-environment"><a name="polyglot"></a>Polyglot Environment</h2>

<p><strong>Unite we stand</strong>. Each language has its strengths, for example Python for machine learning, Node.js for web. With a built in <code class="prettyprint">Socket.io</code> client logic, AIVA allows you to write in multiple coordinating languages.</p>

<p>For now we have <code class="prettyprint">/lib/client.{js, py, rb}</code>. Feel free to add <code class="prettyprint">Socket.io</code> client for more languages through pull request!</p>

<aside class="notice">
Note that the examples below are no longer included, but can be found in aiva v3.2.1
</aside>

<blockquote>
<p>For quick multilingual dev, you can start the <strong>polyglot server</strong> at <code class="prettyprint">src/start-io.js</code> with:</p>
</blockquote>
<pre class="highlight shell"><code><span class="c"># shell: start the polyglot server</span>
npm run server
</code></pre>

<aside class="warning">
This is automatically run with <code>npm run</code>, so don&rsquo;t manual-run it before starting the bot.
</aside>

<blockquote>
<p>then import a <code class="prettyprint">lib/client.js</code> to test a local feature from the <code class="prettyprint">js</code> interface. Example: the snippet at the top of <a href="https://github.com/kengz/aiva/blob/master/scripts/translate.js#L5" target="_blank"><code>scripts/translate.js</code></a> quickly tests the translate function in <code class="prettyprint">python</code>. Uncomment and run it.</p>
</blockquote>
<pre class="highlight javascript"><code><span class="c1">// js: scripts/translate.js</span>
<span class="kr">const</span> <span class="nx">client</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">'../client.js'</span><span class="p">)</span>
<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span> <span class="o">=</span> <span class="nx">client</span><span class="p">.</span><span class="nx">gPass</span>

<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span><span class="p">({</span>
  <span class="na">input</span><span class="p">:</span> <span class="s2">"hola amigos"</span><span class="p">,</span>
  <span class="na">to</span><span class="p">:</span> <span class="s1">'nlp.py'</span><span class="p">,</span>
  <span class="na">intent</span><span class="p">:</span> <span class="s1">'translate'</span>
<span class="p">}).</span><span class="nx">then</span><span class="p">(</span><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">)</span>
<span class="c1">// hello friends</span>
</code></pre>

<aside class="success">
For development like above, <a href="https://github.com/kengz/aiva/tree/master/lib/client.js#L85" target="_blank"><code>lib/client.js</code></a> will automatically set the environment variables using <code>config/</code> if not already.
</aside>

<h2 id="polyglot-development"><a name="polyglot-dev"></a>Polyglot Development</h2>

<p>The quickest way to get into dev is to look at the examples in <code class="prettyprint">lib/&lt;lang&gt;/</code> and <code class="prettyprint">scripts/</code>, which we will go over now.</p>

<p>Development comes down to:</p>

<ul>
<li><strong>module</strong>: callable low level functions, lives in <code class="prettyprint">/lib/&lt;lang&gt;/&lt;module&gt;.&lt;lang&gt;</code>.</li>
<li><strong>interface</strong>: high level user interface to call the module functions, lives in <code class="prettyprint">/scripts/&lt;interface&gt;.js</code></li>
</ul>

<p>The module can be written in any language if it has a Socket.io client. The interface is in <code class="prettyprint">js</code>, and that&rsquo;s pretty easy to write.</p>

<aside class="notice">
It is vital to follow the <a href="#project-dir">directory structure</a> to expose them to socket.io as it calls from <code>lib/&lt;lang&gt;/*</code> but not deeper. You can import nested modules from there and call it with dot-path. More on this later.
</aside>

<p>You write a module in <code class="prettyprint">&lt;lang&gt;</code>, how do you call it from the interface? There are 3 cases depending on the number of <code class="prettyprint">&lt;lang&gt;</code> (including <code class="prettyprint">js</code> for interface) involved.</p>

<h3 id="case-1-lt-lang-gt">Case: 1 <code class="prettyprint">&lt;lang&gt;</code></h3>

<p><code class="prettyprint">&lt;lang&gt; = js</code>. If your module is in <code class="prettyprint">js</code>, just <code class="prettyprint">require</code> it directly in the interface script.</p>

<aside class="notice">
Since the AIVA is based on hubot, you can refer to <a href="https://github.com/github/hubot/blob/master/docs/scripting.md">hubot scripting guide</a>. You can also <a href="https://github.com/github/hubot/blob/master/docs/scripting.md#script-loading">load hubot scripts</a> written by others.
</aside>

<h3 id="case-2-lt-lang-gt-s">Case: 2 <code class="prettyprint">&lt;lang&gt;</code>s</h3>

<p>e.g. <code class="prettyprint">&lt;lang&gt; = js, py</code>. </p>

<p>1. You write a module <a href="https://github.com/kengz/aiva/tree/master/lib/py/hello.py" target="_blank"><code>lib/py/hello.py</code></a></p>

<p>2. Call it from the interface <a href="https://github.com/kengz/aiva/tree/master/scripts/hello_py.js" target="_blank"><code>scripts/hello_py.js</code></a> using the exposed <code class="prettyprint">global.gPass</code> function, with the JSON <code class="prettyprint">msg</code></p>
<pre class="highlight javascript"><code><span class="c1">// js: scripts/hello_py.js</span>
<span class="nx">msg</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">input</span><span class="p">:</span> <span class="s1">'Hello from user.'</span><span class="p">,</span> <span class="c1">// input for module function</span>
  <span class="na">to</span><span class="p">:</span> <span class="s1">'hello.py'</span><span class="p">,</span> <span class="c1">// the target module</span>
  <span class="na">intent</span><span class="p">:</span> <span class="s1">'sayHi'</span> <span class="c1">// the module function to call with input</span>
  <span class="c1">// add more as needed</span>
<span class="p">}</span>
</code></pre>

<p>3. Ensure the called module function returns a reply JSON to the interface:</p>
<pre class="highlight python"><code><span class="c"># py: lib/py/hello.py</span>
<span class="n">reply</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'output'</span><span class="p">:</span> <span class="n">foo</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'input'</span><span class="p">)),</span> <span class="c"># output to interface</span>
  <span class="s">'to'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'from'</span><span class="p">),</span> <span class="c"># is 'client.js' for interface</span>
  <span class="s">'from'</span><span class="p">:</span> <span class="nb">id</span><span class="p">,</span> <span class="c"># 'hello.py'</span>
  <span class="s">'hash'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'hash'</span><span class="p">)</span> <span class="c"># callback hash for interface</span>
<span class="p">}</span>
</code></pre>

<p>The JSON fields above are required for their purposes. <code class="prettyprint">global.gPass</code> used by the interface will auto-inject and <code class="prettyprint">id</code> for reply, and a <code class="prettyprint">hash</code> to resolve the promise for the interface.</p>

<blockquote>
<p>The hello_py feature calls Python; on Telegram:
<img alt="hello_py on Telegram" src="./images/hello_py.png" /></p>
</blockquote>

<h3 id="case-3-lt-lang-gt-s">Case: 3 <code class="prettyprint">&lt;lang&gt;</code>s</h3>

<p>e.g. <code class="prettyprint">&lt;lang&gt; = js, py, rb</code></p>

<p>1. You write modules in <code class="prettyprint">py, rb</code> <a href="https://github.com/kengz/aiva/tree/master/lib/py/hello_rb.py" target="_blank"><code>lib/py/hello_rb.py</code></a>, <a href="https://github.com/kengz/aiva/tree/master/lib/rb/Hello.rb" target="_blank"><code>lib/rb/Hello.rb</code></a></p>

<p>2. Call one (<code class="prettyprint">py</code> in this example) from the interface <a href="https://github.com/kengz/aiva/tree/master/scripts/hello_py_rb.js" target="_blank"><code>scripts/hello_py_rb.js</code></a> as described earlier.</p>

<p>3. <a href="https://github.com/kengz/aiva/tree/master/lib/py/hello_rb.py" target="_blank"><code>lib/py/hello_rb.py</code></a> passes it further to the <code class="prettyprint">rb</code> module, by returning the JSON <code class="prettyprint">msg</code></p>
<pre class="highlight python"><code><span class="c"># py: lib/py/hello_rb.py</span>
<span class="n">reply</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'input'</span><span class="p">:</span> <span class="s">'Hello from Python from js.'</span><span class="p">,</span> <span class="c"># input for rb module function</span>
  <span class="s">'to'</span><span class="p">:</span> <span class="s">'Hello.rb'</span><span class="p">,</span> <span class="c"># the target module</span>
  <span class="s">'intent'</span><span class="p">:</span> <span class="s">'sayHi'</span><span class="p">,</span> <span class="c"># the module function to call with input</span>
  <span class="s">'from'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'from'</span><span class="p">),</span> <span class="c"># pass on 'client.js'</span>
  <span class="s">'hash'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'hash'</span><span class="p">),</span> <span class="c"># pass on callback hash for interface</span>
<span class="p">}</span>
</code></pre>

<p>4. <a href="https://github.com/kengz/aiva/tree/master/lib/rb/Hello.rb" target="_blank"><code>lib/rb/Hello.rb</code></a> ensure the final module function returns a reply JSON <code class="prettyprint">msg</code> to the interface. </p>

<aside class="warning">
For auto-id, Ruby filename need to be the same as its module name, case-sensitive.
</aside>
<pre class="highlight ruby"><code><span class="c1"># rb: lib/rb/Hello.rb</span>
<span class="n">reply</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">'output'</span> <span class="o">=&gt;</span> <span class="s1">'Hello from Ruby.'</span><span class="p">,</span> <span class="c1"># output to interface</span>
  <span class="s1">'to'</span> <span class="o">=&gt;</span> <span class="n">msg</span><span class="p">[</span><span class="s1">'from'</span><span class="p">],</span> <span class="c1"># 'client.js'</span>
  <span class="s1">'from'</span> <span class="o">=&gt;</span> <span class="vc">@@id</span><span class="p">,</span> <span class="c1"># 'Hello.rb'</span>
  <span class="s1">'hash'</span> <span class="o">=&gt;</span> <span class="n">msg</span><span class="p">[</span><span class="s1">'hash'</span><span class="p">]</span> <span class="c1"># callback hash for interface</span>
<span class="p">}</span>
</code></pre>

<blockquote>
<p>The hello_py_rb feature calls Python then Ruby; on Slack:
<img alt="hello_py_rb on Slack" src="./images/hello_py_rb.png" /></p>
</blockquote>

<h3 id="dev-pattern">Dev pattern</h3>

<p>With such pattern, you can chain multiple function calls that bounce among different <code class="prettyprint">&lt;lang&gt;</code>. Example use case: retrieve data from Ruby on Rails app, pass to Java to run algorithms, then to Python for data analysis, then back to Node.js interface.</p>

<aside class="success">
The generic advice: ensure that your functions return the correct JSON <code>msg</code>, and we handle the inter-language dataflow logic. See the <a href="#msg-json"><code>msg</code> JSON keys</a>.
</aside>

<h3 id="quot-ma-look-no-hand-ler-s-quot">&ldquo;Ma look! No hand(ler)s!&rdquo;</h3>

<p>&ldquo;Do I really have to add a handler to reply a JSON <code class="prettyprint">msg</code> for <strong>every</strong> function I call?&rdquo;. That&rsquo;s really cumbersome. </p>

<p>To streamline polyglot development further we&rsquo;ve made the <code class="prettyprint">client.&lt;lang&gt;</code>&rsquo;s automatically try to compile a proper reply JSON <code class="prettyprint">msg</code>, using the original <code class="prettyprint">msg</code> it receives for invoking a function.</p>

<p>What this means is you can call a <strong>module</strong> (<code class="prettyprint">to</code>) by its name, and its <strong>function</strong> (<code class="prettyprint">intent</code>) by specifying the dotpath (if it&rsquo;s nested), then providing a valid <code class="prettyprint">input</code> format (single argument for now).</p>

<p>In fact, <a href="https://github.com/kengz/aiva/tree/master/scripts/translate.js" target="_blank"><code>scripts/translate.js</code></a> does just that. It uses Socket.io to call the <a href="https://github.com/kengz/aiva/tree/master/lib/py/nlp.py" target="_blank"><code>lib/py/nlp.py</code></a>, which imports <a href="https://github.com/kengz/aiva/tree/master/lib/py/ais/ai_lib/translate.py" target="_blank"><code>lib/py/ais/ai_lib/translate.py</code></a></p>

<blockquote>
<p>To test-run it, you can start the <strong>polyglot server</strong> at <code class="prettyprint">src/start-io.js</code> with:</p>
</blockquote>
<pre class="highlight shell"><code><span class="c"># shell: start the polyglot server</span>
npm run server
</code></pre>

<blockquote>
<p>Uncomment the snippet at the top of <a href="https://github.com/kengz/aiva/blob/master/scripts/translate.js#L5" target="_blank"><code>scripts/translate.js</code></a> and run it.</p>
</blockquote>
<pre class="highlight javascript"><code><span class="c1">// js: scripts/translate.js</span>
<span class="kr">const</span> <span class="nx">client</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">'../client.js'</span><span class="p">)</span>
<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span> <span class="o">=</span> <span class="nx">client</span><span class="p">.</span><span class="nx">gPass</span>

<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span><span class="p">({</span>
  <span class="na">input</span><span class="p">:</span> <span class="s2">"hola amigos"</span><span class="p">,</span>
  <span class="na">to</span><span class="p">:</span> <span class="s1">'nlp.py'</span><span class="p">,</span>
  <span class="na">intent</span><span class="p">:</span> <span class="s1">'translate'</span>
<span class="p">}).</span><span class="nx">then</span><span class="p">(</span><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">)</span>
<span class="c1">// hello friends</span>
</code></pre>

<blockquote>
<p>This calls <a href="https://github.com/kengz/aiva/tree/master/lib/py/nlp.py" target="_blank"><code>lib/py/nlp.py</code></a> that imports <a href="https://github.com/kengz/aiva/tree/master/lib/py/ais/ai_lib/translate.py" target="_blank"><code>lib/py/ais/ai_lib/translate.py</code></a>, which returns the translated string instead of a reply JSON. The client will auto-compile a proper reply JSON msg for you.</p>
</blockquote>
<pre class="highlight python"><code><span class="c"># py: lib/py/ais/ai_lib/translate.py</span>
<span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="s">"en"</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">from_lang</span><span class="o">=</span><span class="s">"auto"</span><span class="p">,</span> <span class="n">to_lang</span><span class="o">=</span><span class="n">to</span><span class="p">)</span>
</code></pre>

<blockquote>
<p>The translate feature calls Python that returns string that is auto-compiled into JSON msg by client.py; on Slack:
<img alt="translate on Slack" src="./images/translate.png" /></p>
</blockquote>

<p>On receiving a <code class="prettyprint">msg</code>, the <code class="prettyprint">client.&lt;lang&gt;</code> tries to call the function by passing <code class="prettyprint">msg</code>. If that throws an exception, it retries by passing <code class="prettyprint">msg.input</code>. After the function executes and returns the result, <code class="prettyprint">client.&lt;lang&gt;</code>&rsquo;s handler will check if the reply is a valid JSON, and if not, will make it into one via <code class="prettyprint">correctJSON(reply, msg)</code> by extracting the information needed from the received <code class="prettyprint">msg</code>.</p>

<p>Lastly, after the <code class="prettyprint">js</code> <code class="prettyprint">global.gPass</code> sends out a <code class="prettyprint">msg</code>, the final reply directed at it should contain an <code class="prettyprint">output</code> field, as good dev pattern and reliability in promise-resolution. When <code class="prettyprint">global.gPass(msg)</code> gets its reply and its promise resolved, you will see <code class="prettyprint">hasher.handle invoking cb</code> in stdout.</p>

<aside class="notice">
In fact, once we finish the NLP auto-parsing feature for user sentences, we wouldn&rsquo;t even need to write an interface; This is still under work.
</aside>

<h2 id="unit-tests">Unit Tests</h2>

<p><a href="https://travis-ci.org/kengz/aiva"><img alt="Build Status" src="https://travis-ci.org/kengz/aiva.svg?branch=aiva-v3" /></a> <a href="https://coveralls.io/github/kengz/aiva?branch=master"><img alt="Coverage Status" src="https://coveralls.io/repos/github/kengz/aiva/badge.svg?branch=aiva-v3" /></a></p>

<p>This repo includes only unit tests for <code class="prettyprint">js</code> <strong>modules</strong> and <strong>interface</strong> scripts using <code class="prettyprint">mocha</code>, and runs with <code class="prettyprint">npm test</code>. Note that tests should be for systems, thus the tests for AI models are excluded.</p>

<p>For the module of other <code class="prettyprint">&lt;lang&gt;</code>, you may add any unit testing framework of your choice.</p>

<h2 id="how-it-works-socket-io-logic-and-standard">How it works: Socket.io logic and standard</h2>

<h3 id="msg-json-keys-for-different-purposes"><a name="msg-json"></a><code class="prettyprint">msg</code> JSON keys for different purposes.</h3>

<ul>
<li>to call a module&rsquo;s function in <code class="prettyprint">&lt;lang&gt;</code>: <a href="https://github.com/kengz/aiva/tree/master/scripts/hello_py.js" target="_blank"><code>scripts/hello_py.js</code></a></li>
</ul>
<pre class="highlight javascript"><code><span class="c1">// js: scripts/hello_py.js</span>
<span class="nx">msg</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">input</span><span class="p">:</span> <span class="s1">'Hello from user.'</span><span class="p">,</span> <span class="c1">// input for module function</span>
  <span class="na">to</span><span class="p">:</span> <span class="s1">'hello.py'</span><span class="p">,</span> <span class="c1">// the target module</span>
  <span class="na">intent</span><span class="p">:</span> <span class="s1">'sayHi'</span> <span class="c1">// the module function to call with input</span>
  <span class="c1">// add more as needed</span>
<span class="p">}</span>
</code></pre>

<ul>
<li>to reply the payload to sender: <a href="https://github.com/kengz/aiva/tree/master/lib/py/hello.py" target="_blank"><code>lib/py/hello.py</code></a></li>
</ul>
<pre class="highlight python"><code><span class="c"># py: lib/py/hello.py</span>
<span class="n">reply</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'output'</span><span class="p">:</span> <span class="n">foo</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'input'</span><span class="p">)),</span> <span class="c"># output to interface</span>
  <span class="s">'to'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'from'</span><span class="p">),</span> <span class="c"># is 'client.js' for interface</span>
  <span class="s">'from'</span><span class="p">:</span> <span class="nb">id</span><span class="p">,</span> <span class="c"># 'hello.py'</span>
  <span class="s">'hash'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'hash'</span><span class="p">)</span> <span class="c"># callback hash for interface</span>
<span class="p">}</span>
</code></pre>

<ul>
<li>to pass on payload to other module&rsquo;s function: <a href="https://github.com/kengz/aiva/tree/master/lib/py/hello_rb.py" target="_blank"><code>lib/py/hello_rb.py</code></a></li>
</ul>
<pre class="highlight python"><code><span class="c"># py: lib/py/hello_rb.py</span>
<span class="n">reply</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'input'</span><span class="p">:</span> <span class="s">'Hello from Python from js.'</span><span class="p">,</span> <span class="c"># input for rb module function</span>
  <span class="s">'to'</span><span class="p">:</span> <span class="s">'Hello.rb'</span><span class="p">,</span> <span class="c"># the target module</span>
  <span class="s">'intent'</span><span class="p">:</span> <span class="s">'sayHi'</span><span class="p">,</span> <span class="c"># the module function to call with input</span>
  <span class="s">'from'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'from'</span><span class="p">),</span> <span class="c"># pass on 'client.js'</span>
  <span class="s">'hash'</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'hash'</span><span class="p">),</span> <span class="c"># pass on callback hash for interface</span>
<span class="p">}</span>
</code></pre>

<h3 id="msg-json-keys"><code class="prettyprint">msg</code> JSON keys</h3>

<table><thead>
<tr>
<th style="text-align: left">key</th>
<th>details</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">input</td>
<td>input to the target module function.</td>
</tr>
<tr>
<td style="text-align: left">to</td>
<td>filename of the target module in <code class="prettyprint">lib/&lt;lang&gt;</code>.</td>
</tr>
<tr>
<td style="text-align: left">intent</td>
<td>function of the target module to call. Call nested function with dot-path, e.g. <code class="prettyprint">nlp.translate</code>.</td>
</tr>
<tr>
<td style="text-align: left">output</td>
<td>output from the target function to reply with.</td>
</tr>
<tr>
<td style="text-align: left">from</td>
<td>ID of the script sending the <code class="prettyprint">msg</code>.</td>
</tr>
<tr>
<td style="text-align: left">hash</td>
<td>auto-generated callback-promise hash from <code class="prettyprint">client.js</code> to callback interface.</td>
</tr>
</tbody></table>

<p>Of course, add additional keys to the JSON as needed by your function.</p>

<aside class="notice">
Overall, ensure that your functions return the correct JSON `msg`, and we handle the inter-language dataflow logic.
</aside>

<aside class="success">
Socket.io can send deeply nested JSON with standard data type.
</aside>

<h3 id="server">Server</h3>

<p>There is a socket.io server that extends Hubot&rsquo;s Express.js server: <a href="https://github.com/kengz/aiva/tree/master/lib/io_server.js" target="_blank"><code>lib/io_server.js</code></a>. All <code class="prettyprint">msg</code>s go through it. For example, let <code class="prettyprint">msg.to = &#39;hello.py&#39;, msg.intent = &#39;sayHi&#39;</code>. The server splits this into <code class="prettyprint">module = &#39;hello&#39;, lang = &#39;py&#39;</code>, modifies <code class="prettyprint">msg.to = module</code>, then sends the <code class="prettyprint">msg</code> to the client of <code class="prettyprint">lang</code>.</p>

<blockquote>
<p>For quick multilingual dev, you can start the <strong>polyglot server</strong> at <code class="prettyprint">src/start-io.js</code> with:</p>
</blockquote>
<pre class="highlight shell"><code><span class="c"># shell: start the polyglot server</span>
npm run server
</code></pre>

<aside class="warning">
This is automatically with <code>npm run</code>, so don&rsquo;t manual-run it before starting the bot.
</aside>

<h3 id="clients"><a name="clients"></a>Clients</h3>

<p>For each language, there is a socket.io client that imports all modules of its language within <code class="prettyprint">lib</code>. When server sends a <code class="prettyprint">msg</code> to it, the client&rsquo;s <code class="prettyprint">handle</code> will find the module and its function using <code class="prettyprint">msg.to, msg.intent</code> respectively, then call the function with <code class="prettyprint">msg</code> as the argument. If it gets a valid reply <code class="prettyprint">msg</code>, it will pass it on to the server.</p>

<blockquote>
<p>then import a <code class="prettyprint">lib/client.js</code> to test a local feature from the <code class="prettyprint">js</code> interface. Example: the snippet at the top of <a href="https://github.com/kengz/aiva/blob/master/scripts/translate.js#L5" target="_blank"><code>scripts/translate.js</code></a> quickly tests the translate function in <code class="prettyprint">python</code>. Uncomment and run it.</p>
</blockquote>
<pre class="highlight javascript"><code><span class="c1">// js: scripts/translate.js</span>
<span class="kr">const</span> <span class="nx">client</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">'../client.js'</span><span class="p">)</span>
<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span> <span class="o">=</span> <span class="nx">client</span><span class="p">.</span><span class="nx">gPass</span>

<span class="nx">global</span><span class="p">.</span><span class="nx">gPass</span><span class="p">({</span>
  <span class="na">input</span><span class="p">:</span> <span class="s2">"hola amigos"</span><span class="p">,</span>
  <span class="na">to</span><span class="p">:</span> <span class="s1">'nlp.py'</span><span class="p">,</span>
  <span class="na">intent</span><span class="p">:</span> <span class="s1">'translate'</span>
<span class="p">}).</span><span class="nx">then</span><span class="p">(</span><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">)</span>
<span class="c1">// hello friends</span>
</code></pre>

<aside class="success">
For development like above, <a href="https://github.com/kengz/aiva/tree/master/lib/client.js#L85" target="_blank"><code>lib/client.js</code></a> will automatically set the environment variables using <code>config/</code> if not already.
</aside>

<blockquote>
<p>Note due to how a module is called using <code class="prettyprint">msg.to, msg.intent</code>, you must ensure that the functions are named properly, and <code class="prettyprint">Ruby</code>&rsquo;s requirement that module be capitalized implies that you have to name the file with the same capitalization, e.g. <code class="prettyprint">lib/rb/Hello.rb</code> for the <code class="prettyprint">Hello</code> module.</p>
</blockquote>

<p>We now support <code class="prettyprint">node.js, python, ruby</code>.</p>

<aside class="notice">
To add support for other language, say Java, you can add a <code>lib/client.java</code> by following patterns in <code>lib/client.{py, rb}</code>, and starting them in <code>lib/io_client.js</code>. Please create a pull request if you do so :)
</aside>

<h3 id="entry-point">Entry point</h3>

<p>The entry point is always a <code class="prettyprint">js</code> interface script, but luckily we have made it trivial for non-js developers to write it. A full reference is <a href="https://github.com/github/hubot/blob/master/docs/scripting.md">hubot scripting guide</a>.</p>

<p><code class="prettyprint">robot.respond</code> takes a regex and a callback function, which executes when the regex matches the string the robot receives. <code class="prettyprint">res.send</code> is the primary method we use to send a string to the user.</p>

<p>Overall, there are 2 ways to connect with <code class="prettyprint">lib</code> modules:</p>

<p><strong>global.gPass</strong>: <a href="https://github.com/kengz/aiva/tree/master/scripts/hello_py.js" target="_blank"><code>scripts/hello_py.js</code></a> This is a global method to pass a <code class="prettyprint">msg</code>. It generates a <code class="prettyprint">hash</code> using <code class="prettyprint">lib/hasher.js</code> with a <code class="prettyprint">Promise</code>, which is resolved whenever the <code class="prettyprint">js</code> client receives a valid reply <code class="prettyprint">msg</code> with same <code class="prettyprint">hash</code>. This method returns the resolved <code class="prettyprint">Promise</code> with that <code class="prettyprint">msg</code> for chaining.</p>

<p><strong>wrapped global.gPass</strong>: <a href="https://github.com/kengz/aiva/tree/master/scripts/translate.js" target="_blank"><code>scripts/translate.js</code></a>, <a href="https://github.com/kengz/aiva/tree/master/lib/js/nlp.js" target="_blank"><code>lib/js/nlp.js</code></a> This is similar to above, but the <code class="prettyprint">msg</code> is properly generated by a <code class="prettyprint">js</code> lib module, resulting in a much cleaner and safer interface script. The lib module needs to be imported at the top to be used.</p>

<h3 id="data-flow">Data flow</h3>

<p>The msg goes through socket.io as </p>

<ul>
<li><code class="prettyprint">js(interface script)</code></li>
<li><code class="prettyprint">-&gt; js(io_server.js)</code></li>
<li><code class="prettyprint">-&gt; &lt;lang&gt;(client.&lt;lang&gt;)</code></li>
<li><code class="prettyprint">-&gt; js(io_server.js)</code></li>
<li><code class="prettyprint">-&gt; ...(can bounce among different &lt;lang&gt; modules)</code></li>
<li><code class="prettyprint">-&gt; js(client.js)</code></li>
<li><code class="prettyprint">-&gt; js(interface script)</code></li>
</ul>

<p>For the <code class="prettyprint">hello_py.js</code> example, the path is </p>

<ul>
<li><code class="prettyprint">js(scripts/hello_py.js) user input</code></li>
<li><code class="prettyprint">-&gt; js(lib/io_server.js)</code></li>
<li><code class="prettyprint">-&gt; py(client.py), call py function</code></li>
<li><code class="prettyprint">-&gt; js(io_server.js)</code></li>
<li><code class="prettyprint">-&gt; js(client.js) call Promise.resolve</code></li>
<li><code class="prettyprint">-&gt; js(interface script) send back to user</code></li>
</ul>

<h2 id="project-directory-structure"><a name="project-dir"></a>Project directory structure</h2>

<p>What goes where:</p>

<table><thead>
<tr>
<th style="text-align: left">Folder/File</th>
<th>Purpose</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">bin/</td>
<td>Binary executables</td>
</tr>
<tr>
<td style="text-align: left">config/</td>
<td>credentials</td>
</tr>
<tr>
<td style="text-align: left">db/</td>
<td>Database migration files, models</td>
</tr>
<tr>
<td style="text-align: left">lib/&lt;lang&gt;/</td>
<td>Module scripts, grouped by language, callable via socket.io. See <a href="#polyglot-dev">Polyglot Development</a>.</td>
</tr>
<tr>
<td style="text-align: left">src/</td>
<td>core bot logic</td>
</tr>
<tr>
<td style="text-align: left">logs</td>
<td>Logs from bot for debugging and healthcheck.</td>
</tr>
<tr>
<td style="text-align: left">scripts</td>
<td>The <code class="prettyprint">node.js</code> user interface for the <code class="prettyprint">lib/</code> modules.</td>
</tr>
<tr>
<td style="text-align: left">scripts/_init.js</td>
<td>Kicks off AIVA setups after the base Hubot is constructed, before other scripts are lodaded.</td>
</tr>
<tr>
<td style="text-align: left">test</td>
<td>Unit tests; uses Mocha.</td>
</tr>
<tr>
<td style="text-align: left">external-scripts.json</td>
<td>You can <a href="https://github.com/github/hubot/blob/master/docs/scripting.md#script-loading">load Hubot npm modules</a> by specifying them in here and <code class="prettyprint">package.json</code>.</td>
</tr>
</tbody></table>

          <h1 id="setup-tips"><a name="setup-tips"></a>Setup tips</h1>

<h2 id="docker-installation"><a name="docker-installation"></a>Docker installation</h2>

<p><a href="https://www.docker.com/">Docker</a> is a nice way to package and distribute complex modules, it also allows you to develop in safe isolated environment with containerization. </p>

<p>The <a href="https://hub.docker.com/r/kengz/aiva/">AIVA Docker image</a> (1Gb) comes ready-to-run for the repo source code, same as if ran locally.</p>

<h3 id="ubuntu">Ubuntu</h3>

<ul>
<li>Digital Ocean: The easiest, using their <a href="https://www.digitalocean.com/features/one-click-apps/docker/">Docker 1-click app on Ubuntu</a>. Docker comes installed with it.</li>
<li>Ubuntu from scratch: See <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04">this guide</a> by Digital Ocean.</li>
</ul>

<p>Then, you need <code class="prettyprint">nodejs</code> to run basic setup for entering Docker.</p>
<pre class="highlight shell"><code><span class="c"># Nodejs</span>
curl -sL https://deb.nodesource.com/setup_6.x | bash -
sudo apt-get install -y nodejs
</code></pre>

<p>If your Digital Ocean instance has insufficient swap memory, boost it:</p>
<pre class="highlight shell"><code><span class="c"># Ensure you have enough swap memory. Typically you'd have to run this</span>
<span class="c"># Setting 1Gb swap space.</span>
swapoff -a
sudo dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/swapfile <span class="nv">bs</span><span class="o">=</span>1024 <span class="nv">count</span><span class="o">=</span>1024k
sudo mkswap /swapfile
sudo swapon /swapfile
swapon -s
</code></pre>

<h3 id="mac-osx">Mac OSX</h3>

<p>Mac needs a VM driver on top to run Docker. Here&rsquo;s the complete Docker installation, with <code class="prettyprint">nodejs</code></p>
<pre class="highlight shell"><code><span class="c"># Install Homebrew</span>
ruby -e <span class="s2">"</span><span class="k">$(</span>curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install<span class="k">)</span><span class="s2">"</span>
<span class="c"># Install Cask</span>
brew install caskroom/cask/brew-cask
<span class="c"># Install docker toolbox</span>
brew cask install dockertoolbox

<span class="c"># create the docker machine. Note that 'default' is the vm name we will be using</span>
docker-machine create --driver virtualbox default
<span class="c"># allocate resource for the docker machine when stopped</span>
VBoxManage modifyvm default --cpus 2 --memory 4096
docker-machine start default

<span class="c"># to use vm in terminal</span>
<span class="nb">echo</span> <span class="s1">'eval "$(docker-machine env default)"'</span> &gt;&gt; ~/.bash_profile
<span class="nb">source</span> ~/.bash_profile

<span class="c"># Nodejs</span>
brew install node
npm update npm -g
</code></pre>

<h2 id="custom-deployment">Custom deployment</h2>

<p>All bot deployment commands are wrapped with <code class="prettyprint">npm</code> inside <code class="prettyprint">package.json</code>. For more novice users, you can customize the <code class="prettyprint">scripts</code> in <code class="prettyprint">package.json</code>. For example, changing &ldquo;aiva&rdquo; and &ldquo;aivadev&rdquo; to your bot name of choice.</p>

<h2 id="monitoring">Monitoring</h2>

<p>AIVA uses [<code class="prettyprint">supervisord</code>] with Docker, and <a href="https://github.com/foreverjs/forever"><code class="prettyprint">forever</code></a> without Docker. Either way, the bot logs are written to <code class="prettyprint">logs/</code>.</p>

<p>Additionally, the non-bot logs are written to <code class="prettyprint">/var/log/</code> for <code class="prettyprint">supervisor</code>, <code class="prettyprint">nginx</code> and <code class="prettyprint">neo4j</code> in Docker.</p>

<h2 id="dockerization"><a name="dockerization"></a>Dockerization</h2>

<aside class="notice">
Advanced users can use this section to configure and extend AIVA.
</aside>

<p>With some spirit of try-hard devops, we package the Docker image so it follows common deployment practices. Below are the primary processes that are ran in the Docker container, and the relevant config files. They package the original AIVA that is ran on a local machine into Docker.</p>

<ul>
<li><code class="prettyprint">supervisord</code>, with <code class="prettyprint">bin/supervisord.conf</code>: The main entry-point process that runs everything else. Logs output to the main bash session started by <code class="prettyprint">npm start</code></li>
<li><code class="prettyprint">nginx</code>, with <code class="prettyprint">bin/nginx.conf</code>: Helps expose the Docker port to the host machine and the outside world. See <a href="#docker-port">Docker Port-forwarding</a> for how it&rsquo;s done.</li>
</ul>

<p>Helper bash scripts for running <a href="#commands">Commands</a>;</p>

<ul>
<li><code class="prettyprint">bin/start.sh</code> ran by <code class="prettyprint">npm start</code>: start a container in <code class="prettyprint">production</code> or <code class="prettyprint">development</code> environment, with the primary bash session to use <code class="prettyprint">supervisord</code> only.</li>
<li><code class="prettyprint">bin/enter.sh</code> ran by <code class="prettyprint">npm run enter</code>: start a parallel non-primary bash session to enter the container.</li>
<li><code class="prettyprint">bin/stop.sh</code> ran by <code class="prettyprint">npm stop</code>: stop a container and the bot inside.</li>
<li><code class="prettyprint">bin/reset.sh</code> ran by <code class="prettyprint">npm run reset</code>: stop and remove a container, so you can create a fresh one with <code class="prettyprint">npm start</code> if shit goes wrong.</li>
</ul>

<h2 id="docker-port-forwarding"><a name="docker-port"></a>Docker Port-forwarding</h2>

<p>In the uncommon case where you need to expose a port from Docker, there are 4 steps:</p>

<ul>
<li>EXPOSE the port and its suggorate in <code class="prettyprint">bin/Dockerfile</code>, then rebuild the Docker image for changes to apply.</li>
<li>define the reverse proxy for the port following the pattern in <code class="prettyprint">bin/nginx.conf</code></li>
<li>for MacOSX, add the ports for host-container port forwarding by Virtualbox in <code class="prettyprint">bin/start.sh</code> above <code class="prettyprint">VBoxManage controlvm ...</code></li>
<li>publish the Docker port in <code class="prettyprint">bin/start.sh</code> at <code class="prettyprint">docker run ... -p &lt;hostport&gt;:&lt;containerport&gt;</code></li>
</ul>

<h2 id="webhook-using-ngrok"><a name="ngrok"></a>Webhook using ngrok</h2>

<p>You don&rsquo;t need to specify any webhook urls; they are set up automatically in <a href="https://github.com/kengz/aiva/blob/master/index.js#L86" target="_blank"><code>index.js with ngrok</code></a>. Access the ngrok interface at <a href="http://localhost:4040"><code class="prettyprint">http://localhost:4040</code></a> (production) or <a href="http://localhost:4041"><code class="prettyprint">http://localhost:4041</code></a> (development) after AIVA is run.</p>

<p>Note that for each adapter, if it needs a webhook, you need to specify the <code class="prettyprint">PORT</code> and the environment key for the webhook, from <code class="prettyprint">config/</code>.</p>

<p>If the webhook environment key is not specified, then ngrok will assign it a random emphemeral web url. This is especially useful if you wish to specify a Heroku url, or a custom ngrok url. </p>

<blockquote>
<p>For example, since Facebook takes 10 minutes to update a webhook, we wish to use a persistent webhook url. We leave Telegram to a random url generated by ngrok.</p>
</blockquote>
<pre class="highlight shell"><code><span class="c"># FB_WEBHOOK is set as https://aivabot.ngrok.com</span>
<span class="c"># TELEGRAM_WEBHOOK is not net</span>

<span class="c"># ... AIVA is run, Telegram is given a random url</span>
<span class="c"># stdout log</span>
<span class="o">[</span>Wed Jun 01 2016 12:02:33 GMT+0000 <span class="o">(</span>UTC<span class="o">)]</span> INFO telegram webhook url:  https://ddba2b46.ngrok.io at PORT: 8443
<span class="o">[</span>Wed Jun 01 2016 12:02:33 GMT+0000 <span class="o">(</span>UTC<span class="o">)]</span> INFO Deploy bot: AIVAthebot with adapter: telegram
<span class="o">[</span>Wed Jun 01 2016 12:02:33 GMT+0000 <span class="o">(</span>UTC<span class="o">)]</span> INFO fb webhook url:  https://aivadev.ngrok.io at PORT: 8545
<span class="o">[</span>Wed Jun 01 2016 12:02:33 GMT+0000 <span class="o">(</span>UTC<span class="o">)]</span> INFO Deploy bot: aivadev with adapter: fb
</code></pre>

<aside class="notice">
If you use a custom ngrok domain, be sure to <a href="https://ngrok.com/docs#authtoken" target="_blank">install your authtoken before hand</a>. A ngrok custom url cannot be used twice.
</aside>

<aside class="notice">
Remember to use HTTPS urls.
</aside>

<h2 id="ssh-browser-forwarding">SSH Browser-forwarding</h2>

<p>If you&rsquo;re hosting Neo4j on a remote machine and want to access its browser GUI on your local machine, connect to it via </p>
<pre class="highlight shell"><code>ssh -L 8080:localhost:7474 &lt;remote_host&gt;
</code></pre>

<p>Then you can go to <code class="prettyprint">http://localhost:8080/</code> on your local browser.</p>

          <h1 id="human-turing-machine-interface"><a name="htmi"></a>Human-Turing Machine Interface</h1>

<p>We present <em>Human-Turing Machine Interface (HTMI)</em> that is human-bounded Turing complete.</p>

<h2 id="design">Design</h2>

<p><strong>HTMI</strong> consists of a human, a Turing Machine, and an interface. The human sends queries and responses to the interface, which maps and canonicalizes them as inputs to the TM. Symmetrically, the TM sends queries and responses to the interface, which verbalizes them as output to the human.</p>

<p>The design outlines of HTMI are as follow:</p>

<ul>
<li>approximate human-human interaction</li>
<li>implement Human-Centered Design (HCD): discoverability (no manual), with affordances, signifiers, mapping</li>
<li>constraints and forcing functions (HCD)</li>
<li>feedback (HCD)</li>
<li>just as we don&rsquo;t see &ldquo;human errors&rdquo; in human-human interaction but to simply ask for clarification, the machine shall do the same. It should treat &ldquo;human error&rdquo; as approximation, ask for clarification, and try to complete the action (HCD). Call this &ldquo;error-resilience&rdquo;, and the machine reaction as &ldquo;inquiry&rdquo;</li>
<li>long-short term memory (LSTM) on both human and TM</li>
<li>TM must approximate human behavior and human-like brain function, using Contextual Graph Knowledge Base (CGKB)</li>
</ul>

<h2 id="theorem">Theorem</h2>

<p><em>HTMI is human-bounded Turing complete.</em></p>

<h4 id="definition">Definition</h4>

<p><strong>Human-bounded Turing complete</strong>: The class which is the intersection between the Turing-complete class and the class of problems enumerable by humans. The latter class bounds its Turing completeness. Note that it may be the Turing complete class itself, if the latter class is bigger than the former.</p>

<h4 id="proof">Proof</h4>

<ol>
<li>Let a HTMI be given. A TM is Turing complete. For practical interpretation, TM is equivalent to a pair <code class="prettyprint">{Fn, I}</code>, where <code class="prettyprint">Fn</code> is the set of functions invokable by a TM with random access of its information <code class="prettyprint">I</code> on its tape.</li>
<li>The interface takes a human input and maps surjectively into <code class="prettyprint">Fn</code>. If the input cannot be mapped, it is rejected by the interface.</li>
<li>For the mapped <code class="prettyprint">fn  Fn</code>, TM computes using <code class="prettyprint">fn, I</code>.</li>
<li>When the TM halts, the interface passes its output to the human, optionally verbalized.</li>
<li>The map above is surjective, mapping from the class of problems enumerable by humans into the TM class.</li>
<li>Since only <code class="prettyprint">fn  Fn</code> are mapped into surjectively and computed, the HTMI class is a subset of the TM class. Since it maps from the class of problems enumerable by humans, the HTMI class is at the intersection between the two classes. Therefore HTMI is human-bounded Turing complete.</li>
</ol>

<h4 id="implication">Implication</h4>

<p>The theorem establishes that HTMI can be used by a human to solve any problems or perform any functions she enumerates that are solvable by a TM. For practical purposes, we focus on decidable problems.</p>

          <h1 id="contextual-graph-knowledge-base"><a name="cgkb"></a>Contextual Graph Knowledge Base</h1>

<p>We present <em>Contextual Graph Knowledge Base (CGKB)</em> as the TM memory implementation of <em>HTMI</em>. This shall be consistent with design outlines of <em>HTMI</em></p>

<h2 id="design">Design</h2>

<p>Recall that TM is equivalent to <code class="prettyprint">{Fn, I}</code>, where <code class="prettyprint">Fn</code> is the set of functions invokable by a TM with random access of its information <code class="prettyprint">I</code> on its tape. CGKB serves as the implementation for <code class="prettyprint">I</code>. To also satisfy the approximation of human-human interaction, we have the following design outlines:</p>

<ul>
<li><p><strong>graph</strong>: just as all enumerable data types, this supports TM completeness. Besides, its generality and features are established mathematically, and this will be easier to use given the connected nature of knowledge. <code class="prettyprint">Fn</code> includes generic TM functions and graph operations on <code class="prettyprint">I</code>, which is information encoded in graph nodes and edges that richly represent properties and relationships.</p></li>
<li><p><strong>context</strong>: the collective term for fundamental information types. To make TM operations tractable, contextualization restricts the scope to a manageable subgraph. The context filters are: privacy (public/private knowledge), entity, ranking, time, constraints, graph properties. </p></li>
<li><p><strong>ranking</strong>: graph indexing analogous to how humans rank memories, for tractability. Ranking can use emotions (human analogy), LSTM (long-short term memories) for quick graph search.</p></li>
<li><p><strong>learning</strong>: consistent with the &ldquo;inquiry&rdquo; feature of HTMI, CGKB will extend itself by inquiring for missing information.</p></li>
</ul>

<h4 id="terminologies">Terminologies</h4>

<ul>
<li><strong>auto-planning</strong>: the brain can build up and provide plans as causal graph automatically, such as in the simple case of getting a friend&rsquo;s phone number, or in the more complex case of playing chess. This utilizes all features of the brain enumerated above.</li>
<li><strong>canonicalized input</strong> <code class="prettyprint">&lt;fn, i_p&gt;</code>: where <code class="prettyprint">fn</code> is a TM function, and <code class="prettyprint">i_p</code> the partial information needed for <code class="prettyprint">fn</code>&rsquo;s functional arguments. The output of the interface in HTMI on taking human input, for the TM to use. CGKB will attempt to extract the full information <code class="prettyprint">i</code> required for <code class="prettyprint">fn</code>.</li>
<li><strong>causality</strong>: The directed structure of the graph. Used in search, planning, dependencies, chronology, etc.</li>
<li><strong>cognition</strong>: graph operations as <code class="prettyprint">Fn</code> on <code class="prettyprint">I</code>, to mimic human cognition.</li>
<li><strong>constraint</strong>: e.g. existence, soundness.</li>
<li><strong>function execution</strong> <code class="prettyprint">fn(i)</code>: Execute TM function <code class="prettyprint">fn  Fn</code> on information <code class="prettyprint">i  I</code> to yield output</li>
<li><strong>graph</strong>: the entire CGKB graph</li>
<li><strong>norm</strong>: preferred defaults to resolve ambiguities.</li>
<li><strong>plan</strong>: The causal graph of the necessary information in <code class="prettyprint">I</code> to execute in <code class="prettyprint">Fn</code>.</li>
<li><strong>plan execution</strong>: Extraction of information by traversing plan in reverse causal order from leaves to root, using the supplied <code class="prettyprint">i_p</code> and contexts. Returns a subgraph for the extraction of <code class="prettyprint">i</code></li>
</ul>

<h2 id="formal-theory">Formal Theory</h2>

<h4 id="definitions">Definitions</h4>

<ul>
<li><code class="prettyprint">g</code>: The entire graph of CGKB</li>
<li><code class="prettyprint">g_i</code>, <code class="prettyprint">h</code>: placeholder for any subgraph of <code class="prettyprint">g</code></li>
<li><code class="prettyprint">Contextualize</code>: the Contextualize algorithm</li>
<li><code class="prettyprint">c_0</code>: the initial context, determined from <code class="prettyprint">fn, i_p</code></li>
<li><code class="prettyprint">&lt;fn, i_p&gt;</code>: the canonicalized input from the interface of HTMI after parsing a human input, where <code class="prettyprint">fn</code> is a TM function, and <code class="prettyprint">i_p</code> the partial information needed for <code class="prettyprint">fn</code>&rsquo;s execution.</li>
<li><code class="prettyprint">filter</code>: fields used to filter context, i.e. constrain the expansion of initial context in the <code class="prettyprint">Contexualize</code> algorithm; thus far they are <code class="prettyprint">{privacy, entity, ranking, time, constraints, graph properties}</code></li>
<li><code class="prettyprint">scope</code>: the lists of fulfilled and unfulfilled information, <code class="prettyprint">scope_f, i_u</code> respectively for the extraction of <code class="prettyprint">i</code> for <code class="prettyprint">fn(i)</code>.</li>
<li><code class="prettyprint">c</code>: contextual (knowledge) graph, or the contextualized subgraph, i.e. the output <code class="prettyprint">Contextualize(g, c_0, i_p)</code>; <code class="prettyprint">c  g</code></li>
<li><code class="prettyprint">i  I</code>: the complete information needed to compute <code class="prettyprint">fn(i)</code>. It is encoded within <code class="prettyprint">g</code>; obviously there exists a smallest subgraph <code class="prettyprint">h  g</code> that sufficiently encodes <code class="prettyprint">i</code>. Equivalently <code class="prettyprint">i</code> is the union of partial information <code class="prettyprint">i_1, i_2, ...</code></li>
<li><code class="prettyprint">k</code>: knowledge, i.e. the complete information extractable from <code class="prettyprint">g</code>. Note <code class="prettyprint">i  k</code>, but <code class="prettyprint">fn(i) = fn(k)</code> since the TM function <code class="prettyprint">fn</code> only computes using the needed information.</li>
<li><code class="prettyprint">k_h</code>: the information extractable from subgraph <code class="prettyprint">h  g</code>. Note <code class="prettyprint">k = k_g</code>.</li>
<li><code class="prettyprint">Ex</code>: the extraction operator to extract knowledge from a graph, e.g. <code class="prettyprint">k = Ex(g), k_h = Ex(h)</code></li>
<li><code class="prettyprint">-*-&gt;</code>: graph path, or &lsquo;derives&rsquo;. We say <code class="prettyprint">g_1 -*-&gt; g_2</code> if <code class="prettyprint">g_1</code> is connected to <code class="prettyprint">g_2</code>, and <code class="prettyprint">k_1 -*-&gt; k_2</code> if <code class="prettyprint">k_1</code> derives <code class="prettyprint">k_2</code>.</li>
</ul>

<h4 id="axioms">Axioms</h4>

<blockquote>
<ol>
<li>Knowledge is encoded in a graph <code class="prettyprint">g</code>, and decoded using the <code class="prettyprint">Ex</code> operator.</li>
<li>Knowledge is deriverable, and this is reflected in its graph encoding by connectedness. Let <code class="prettyprint">k_1 = Ex(g_1), k_2 = Ex(g_2)</code>, if <code class="prettyprint">k_1 derives k_2</code>, i.e. <code class="prettyprint">k_1 -*-&gt; k_2</code>, then there must exists a corresponding path <code class="prettyprint">g_1 -*-&gt; g_2</code>, s.t. <code class="prettyprint">(k_1  k_2)</code> is extractable from the connected component CC of <code class="prettyprint">g_1</code>, i.e. <code class="prettyprint">(k_1  k_2)  Ex(CC(g_1))</code>.</li>
<li>Base knowledge (graph sink) is the most basic knowledge, and is the source of the derivation path. If the path is cyclic, arbitrarily choose the last-encountered node as the basic knowledge. Base knowledge resolves all knowledge along the derivation path by gradual substitutions.</li>
</ol>
</blockquote>

<h2 id="contextualize-algorithm">Contextualize algorithm</h2>

<p>Let there be given graph <code class="prettyprint">g</code>, initial context <code class="prettyprint">c_0</code>, partial information <code class="prettyprint">i_p</code>.</p>

<p><strong>input</strong>: <code class="prettyprint">g, c_0, i_p</code></p>

<p><strong>output</strong>: contextual knowledge graph <code class="prettyprint">c</code></p>

<p><strong>enumerate</strong>:</p>

<ol>
<li>Initialize <code class="prettyprint">scope</code> from <code class="prettyprint">c_0, i_p</code></li>
<li>while <code class="prettyprint">scope</code> is not completely fulfilled, do:

<ol>
<li>BFS expansion on <code class="prettyprint">c_0</code> using the unfulfilled scope, <code class="prettyprint">filters</code> and <code class="prettyprint">i_p</code>, and</li>
<li>if context is expanded, update scope, continue; </li>
<li>else, apply <code class="prettyprint">learning</code> with <code class="prettyprint">inquire</code> to expand <code class="prettyprint">g</code> (but not context and scope); then retry on success or break on failure.</li>
</ol></li>
<li>Return the context <code class="prettyprint">c</code>, along with the fulfilled scope for direct access of <code class="prettyprint">i</code>.</li>
</ol>

<p>We also call the resulting context <code class="prettyprint">c</code> the contextual knowledge graph, and the extractable knowledge <code class="prettyprint">k_c = Ex(c)</code> the contextual knowledge, obtained by using <code class="prettyprint">g, c_0, i_p, filters</code>. Note also <code class="prettyprint">fn(i) = fn(k_c)</code>, thus the resulting contextual knowledge is sufficient for TM computation.</p>

<p>We prove below that this algorithm yields knowledge that is <code class="prettyprint">g-bounded complete</code>; it also proves that the algorithm is correct.</p>

<h2 id="g-bounded-completeness-theorem">g-bounded Completeness Theorem</h2>

<h4 id="facts">Facts</h4>

<ol>
<li>The initial context <code class="prettyprint">c_0</code> can be disjoint (multiple graph components)</li>
<li>Thus the resulting context <code class="prettyprint">c</code> can also be a graph with disjoint components, each containing at least a node from <code class="prettyprint">c_0</code>.</li>
<li>The resulting context <code class="prettyprint">c</code> is due to the provided <code class="prettyprint">g, c_0, i_p, filters</code>.</li>
</ol>

<h4 id="definition">Definition</h4>

<p>Let there be given canonicalized input <code class="prettyprint">&lt;fn, i_p&gt;</code> with TM function <code class="prettyprint">fn</code>, partial information <code class="prettyprint">i_p</code>, graph <code class="prettyprint">g</code>, initial context <code class="prettyprint">c_0</code>, and let context <code class="prettyprint">c = Contextualize(g, c_0, i_p)</code>, and its extracted knowledge <code class="prettyprint">k_c = Ex(c)</code>. Let <code class="prettyprint">k_g = Ex(g)</code> be the complete knowledge extractable from <code class="prettyprint">g</code>.</p>

<blockquote>
<p>We say <code class="prettyprint">k_c</code> is <code class="prettyprint">g-bounded complete</code> <em>iff</em> <code class="prettyprint">fn(k_c) = fn(k_g)</code>.</p>
</blockquote>

<h4 id="lemma">Lemma</h4>

<blockquote>
<p><code class="prettyprint">k_g</code> is <code class="prettyprint">g-bounded complete</code>.</p>
</blockquote>

<p><strong>Proof</strong>: <code class="prettyprint">fn(k_g) = fn(k_g)</code> by identity. </p>

<h4 id="theorem">Theorem</h4>

<blockquote>
<p><code class="prettyprint">k_c</code> is <code class="prettyprint">g-bounded complete</code>.</p>
</blockquote>

<p><strong>Proof</strong>: The initial context <code class="prettyprint">c_0</code> is obtained from <code class="prettyprint">&lt;fn, i_p&gt;</code>. The <code class="prettyprint">scope</code> of the <code class="prettyprint">Contextualize</code> algorithm is initialized with all the necessary information needed for the resulting context and <code class="prettyprint">fn</code>. </p>

<p>When the algorithm terminates with all the scopes fulfilled, by the axioms, we obtain in <code class="prettyprint">c</code> all the necessary basic knowledge to resolve <code class="prettyprint">c_0</code> entirely, thus yielding the necessary and sufficient <code class="prettyprint">i</code> for <code class="prettyprint">fn(i)</code>. The algorithm is correct.</p>

<p>The context <code class="prettyprint">c</code> is thus the smallest subgraph in <code class="prettyprint">g</code> that encodes the complete information <code class="prettyprint">i</code> needed to compute <code class="prettyprint">fn(i) = fn(k_c)</code>, thus extending the context any further, even to <code class="prettyprint">g</code>, does not add to the already-complete <code class="prettyprint">i</code>, since we know <code class="prettyprint">fn(k_g) = fn(i)</code>. Thus, combining the two equalities, we get <code class="prettyprint">fn(k_c) = fn(k_g)</code>. </p>

<h2 id="cgkb-algorithm">CGKB algorithm</h2>

<p>Let there be given the graph <code class="prettyprint">g</code> of CGKB, canonicalized input <code class="prettyprint">&lt;fn, i_p&gt;</code> from human input parsed by the interface of HTMI, where <code class="prettyprint">fn</code> is a TM function and <code class="prettyprint">i_p</code> the partial function for executing <code class="prettyprint">fn</code>.</p>

<p><strong>input</strong>: <code class="prettyprint">g, fn, i_p</code></p>

<p><strong>output</strong>: TM output utilizing contextual knowledge <code class="prettyprint">fn(i)</code></p>

<p><strong>enumerate</strong>:</p>

<ol>
<li>Auto-planning: set <code class="prettyprint">plan = Contextualize(g, fn, i_p)</code>.</li>
<li>Contextual knowledge extraction: set <code class="prettyprint">c = Contextualize(g, plan, i_p)</code>.</li>
<li>Extract knowledge <code class="prettyprint">k_c = Ex(c)</code> from <code class="prettyprint">c</code> (and its <code class="prettyprint">scope</code>), compute and return <code class="prettyprint">fn(k_c) = fn(i)</code>.</li>
</ol>

<p><code class="prettyprint">fn</code> is used as the initial context for extracting a <code class="prettyprint">plan</code>. The <code class="prettyprint">plan</code> is used for TM to automatically extract the contextual knowledge needed for computation. This is similar to AI planning, except the plan is already encoded in <code class="prettyprint">g</code> when the CGKB learns, thus the planning is automatic.</p>

<p>The context <code class="prettyprint">c</code> and its <code class="prettyprint">scope</code> are extracted from the <code class="prettyprint">plan</code> (or CGKB learns from the human otherwise). We then extract the contextual knowledge, <code class="prettyprint">k_c</code>, containing information <code class="prettyprint">i  k_c</code>, for computing and returning <code class="prettyprint">fn(k_c) = fn(i)</code>.</p>

<p><strong>Proof</strong>: To prove that the algorithm is correct, we must show that it is <strong>Human-bounded Turing complete</strong>, as outlined in <a href="./HTMI.md">HTMI</a>. If so, CGKB can be used by HTMI.</p>

<p>Recall again that TM is equivalent to <code class="prettyprint">{Fn, I}</code>. We know that knowledge <code class="prettyprint">k</code> or information <code class="prettyprint">i  k</code> is encoded in the graph <code class="prettyprint">g</code> of CGKB. For any <code class="prettyprint">fn  Fn</code>, we can obtain a sufficient context <code class="prettyprint">c</code> such that <code class="prettyprint">i  k_c = Ex(c)</code> for computation <code class="prettyprint">fn(i)</code>. We show below.</p>

<p>The graph <code class="prettyprint">g</code> of CGKB supports TM completeness, and thus without human restrictions, CGKB with TM is TM complete, as spanned by <code class="prettyprint">Fn(I)</code>. </p>

<p>In HTMI, <code class="prettyprint">g</code> is used by queries from a human, which restrict its effective power. Note <code class="prettyprint">g</code> is also built upon the TM&rsquo;s interactions with a human via <code class="prettyprint">learning</code>: and thus <code class="prettyprint">g</code> of CGKB is <strong>Human-bounded Turing complete</strong> inductively: at every step for context <code class="prettyprint">c  g</code>, if CGKB can directly answer to a human, then it is already so; otherwise, it <code class="prettyprint">learns</code> from the human and extends its <code class="prettyprint">g</code> to be so, and it can answer the human with its new knowledge.</p>

<p>Finally, for each <code class="prettyprint">fn  Fn</code> and its corresponding context <code class="prettyprint">c</code>, the contextual knowledge <code class="prettyprint">k_c</code> is <strong>g-bounded complete</strong> by the theorem above, which implies <code class="prettyprint">fn(k_c) = fn(k_g)</code>. So, the context <code class="prettyprint">c</code> is always sufficient for emulating <code class="prettyprint">fn(k_g)</code> for the <strong>Human-bounded Turing complete</strong> <code class="prettyprint">g</code>. Therefore, CGKB is <strong>Human-bounded Turing complete</strong>. </p>

<h2 id="examples">Examples</h2>

<p>We provide simple examples of CGKB below. The real possibilities are only limited by <strong>Human-bounded Turing complete</strong>, as proven above. In principle, one can use the brain for any AI tasks, such as playing chess, acting as a generic knowledge base, perform basic cognition, carry out basic functions. Note that in practice, implementation will need to cover more specific details.</p>

<h4 id="when-g-has-learned-the-knowledge">when <code class="prettyprint">g</code> has learned the knowledge</h4>

<p>Given the graph <code class="prettyprint">g</code> of CGKB that knows how to call a person,</p>

<ul>
<li>Human input: <code class="prettyprint">&quot;Call John.&quot;</code></li>
<li>HTMI interface canonicalize input to: <code class="prettyprint">&lt;fn = call, i_p = &quot;John&quot;&gt;</code>, where <code class="prettyprint">&quot;John&quot;</code> is tagged as <code class="prettyprint">proper noun</code> by a NLP POS Tagger.</li>
<li>Algorithm <code class="prettyprint">CGKB(g, fn = call, i_p = &quot;John&quot;)</code>:

<ol>
<li>Auto-planning: <code class="prettyprint">plan = Contextualize(g, call, &quot;John&quot;) = (call)-[requires]-&gt;(phone_number)-[requires]-&gt;(person)</code></li>
<li>Contextual knowledge extraction: <code class="prettyprint">c = Contextualize(g, plan, &quot;John&quot;) = (me)-[knows]-&gt;(John)</code>, where the node John contains his phone number. As stated in the <code class="prettyprint">Contextualize</code> algorithm, the operation utilizes filters with graph ranking such as emotions, LSTM, time, contraints, or ambiguity resolution, to provide the result context graph <code class="prettyprint">c</code>.</li>
<li>Extract knowledge <code class="prettyprint">k_c = Ex(c) = { name: &quot;John&quot;, phone: &quot;(234)-567-8900&quot;}</code>, and execut the function <code class="prettyprint">call(&quot;(234)-567-8900&quot;)</code>.</li>
</ol></li>
</ul>

<h4 id="when-g-doesn-39-t-have-the-knowledge">when <code class="prettyprint">g</code> doesn&rsquo;t have the knowledge</h4>

<p>Given the graph <code class="prettyprint">g</code> of CGKB that <strong>does not</strong> know how to call a person,</p>

<ul>
<li>Human input: <code class="prettyprint">&quot;Call John.&quot;</code></li>
<li>HTMI interface canonicalize input to: <code class="prettyprint">&lt;fn = call, i_p = &quot;John&quot;&gt;</code>, where <code class="prettyprint">&quot;John&quot;</code> is tagged as <code class="prettyprint">proper noun</code> by a NLP POS Tagger.</li>
<li>Algorithm <code class="prettyprint">CGKB(g, fn = call, i_p = &quot;John&quot;)</code>:

<ol>
<li>Auto-planning: <code class="prettyprint">plan = Contextualize(g, call, &quot;John&quot;) = (call)-[requires]-&gt;(phone_number)</code>. The TM will call <code class="prettyprint">learning</code> to inquire missing information from the human, update <code class="prettyprint">g</code>, and recall the algorithm to yield <code class="prettyprint">(call)-[requires]-&gt;(phone_number)-[requires]-&gt;(person)</code>. The rest follows as before.</li>
<li>Contextual knowledge extraction: Suppose the human doesn&rsquo;t know any &ldquo;John&rdquo;; TM will attempt to learn from the human, update CGKB and continue with the task accordingly. This happens for any missing knowledge.</li>
</ol></li>
</ul>

<h4 id="explain-the-quot-thought-process-quot">explain the &ldquo;thought process&rdquo;</h4>

<p>Another powerful feature of CGKB is that a human can inquire about the TM&rsquo;s thought process, like &ldquo;explain how do you call a person?&rdquo;. In this case, </p>

<ul>
<li><code class="prettyprint">fn = explain_thought_process</code>, </li>
<li><code class="prettyprint">i_p = &quot;how do you call a person?&quot;</code></li>
<li><code class="prettyprint">plan = (explain_thought_process)-[require]-(requirements)...</code></li>
<li><code class="prettyprint">c = (call)-[requires]-&gt;(phone_number)</code></li>
</ul>

<p>And the TM may return <code class="prettyprint">fn(k_c) = &quot;(call)-[requires]-&gt;(phone_number)&quot;</code> and the response.</p>

          <h1 id="changelog"><a name="changelog"></a>Changelog</h1>

<p>Check the <a href="https://github.com/kengz/aiva/releases">Github releases</a>.</p>

<h2 id="legacy-releases">Legacy Releases</h2>

<p>AIVA was known as Jarvis in version 2. It is now deprecated, but if you need to reference stuff from Jarvis, do <code class="prettyprint">git checkout tags/v2.0</code> or checkout <a href="https://github.com/kengz/aiva/releases">the releases</a>.</p>

<p>AIVA v3 was last released at <a href="https://github.com/kengz/aiva/releases/tag/v3.2.1">v3.2.1</a>, which was full featured, but quite heavy. We retire it in favor of a lighter, more developer-friendly and extendible version.</p>

<h1 id="roadmap"><a name="roadmap"></a>Roadmap</h1>

<ul>
<li>a built in graph brain for ad-hoc knowledge encoding, using <a href="http://kengz.me/aiva/#cgkb">CGKB</a> and <a href="http://kengz.me/aiva/#htmi">HTMI</a></li>
<li>a built in NLP intent-parsing engine</li>
</ul>

          <h1 id="contributing"><a name="contributing"></a>Contributing</h1>

<p>We&rsquo;d love for you to contribute and make AIVA even better for all developers. We&rsquo;re mainly interested in something generic and foundational, e.g. adding client for a new language, improving the NLP, adding a useful generic module, adding more adapters like Skype or Twilio.</p>

      </div>
      <div class="dark-box">
          <div class="lang-selector">
          </div>
      </div>
    </div>
  </body>
</html>
